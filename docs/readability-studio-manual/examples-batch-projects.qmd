```{r}
#| include: false
#| eval: true

source('R/appdown.r')
```

# Batch Projects

`r drop_cap('Within')` this chapter, we will step through examples showing how to analyse batches of documents.
This will involve gathering documents from folders, grouping them, and then processing them all at once.
We will also discuss the batches' aggregated results and how to interpret them.

::: {.notesection data-latex=""}
Batch projects are only available in the *Professional* edition of *Readability Studio*.
:::

\newpage

## Reviewing a Collection of Documents

To determine the readability of a document collection, you will need to create a new batch project.
First, click the `r keys("New")` button on the **Home** tab to open the **Select Project Type** dialog, as shown below:

```{r echo=F, fig.align='center', out.width='50%'}
knitr::include_graphics("images/selectprojecttype.png")
```

Select **Batch Project** and click the `r keys("OK")` button to proceed to the **New Project** wizard dialog:

![](images/wizardbatchselectfiles.png)

Select **English** as the document language.
Next, you can add files from a folder, website, spreadsheet, or archive to the project.
We will be reviewing files from a folder, so click the `r keys("Add folder...")` button.
You will be presented with the [**Select Directory**](#sec-batch-project-import-features) dialog:

```{r echo=F, fig.align='center', out.width='75%'}
knitr::include_graphics("images/selectdirectory.png")
```

Enter the path to your document folder in the top field.
We will want to search for files inside of this folder and its subfolders, so leave **Search directories recursively** checked.
Click the `r keys("OK")` button to accept, and you will then be prompted about how to label the documents.
Leave the defaults and click `r keys("OK")` and the program will begin its file search.
After the program is finished searching for documents, you will return to the **New Project Wizard**.
Note how all the files that were found are now included in the file list:

![](images/wizardbatchselectfilesloaded.png)

To add more files from other folders, repeat the previous step.

We will analyze all the documents in this collection, so just ignore the **% of documents to randomly sample** option.
Click the `r keys("Forward >")` button to continue to the **Document Structure** page, as shown below:

![](images/wizarddocstructurenarrativeselected.png)

In this dialog, you will specify the format that best describes your documents.
We are analyzing standard, narrative documents, so select **Narrative text**.
After selecting your document structure, click the `r keys("Forward >")` button to continue to the **Test Selection** page, as shown below:

![](images/wizardbatchreadabilitymethods.png)

On this page, you will select how you want *Readability Studio* to choose the readability tests to perform.
Select the **Recommend tests based on document type**:

![](images/wizardbatchdoctype.png)

We will be analyzing technical documents in this example, so select **Technical document or form**.
Click the `r keys("Finish")` button and the project will be created and will appear like this:

![](images/batchscorestats.png)

The first items presented to us are the aggregated [statistics](#sec-reviewing-batch-scores) for the test scores.
This will give us a general overview of the collection's readability level.
By looking at the **Means** column, we can see that the average reading levels of our documents are in the high-school range.
Also, the mean [Flesch](#sec-flesch-test) score is 54, which is somewhat difficult.
The next column to review is the **Maximum** column.
Here we can see that some of the higher test scores (e.g., 14.6) are into the collegiate level.
From this, we can summarize that this collection is a little too difficult to read and that some documents need revising.

To view a breakdown of all the documents and their respective test scores, click on the **Raw Scores** subitem.
Here we can [sort](#sec-column-sorting) any of the test columns to see which documents scored the highest.

![](images/batchrawscores.png)

To view any document's scores in a vertical layout, double-click on its row in this list to display the **View Item** dialog:

```{r echo=F, fig.align='center', out.width='45%'}
knitr::include_graphics("images/viewitemrawscores.png")
```

The distribution of these raw scores can also be graphically viewed.
Click on the **Score Box Plots** icon on the project sidebar to view the box plots, and click on the **Histograms** icon to view the histograms.
Box plots show the spread of each test's scores, whereas histograms show a test's scores divided into groups.
For example, below is a histogram showing the Flesch-Kincaid scores:

```{r echo=F, fig.align='center', out.width='75%'}
knitr::include_graphics("images/histogrades.png")
```

Judging from this graph, we have quite a few difficult documents in this batch.
There are 11 files in the 12–13 range, which is not a comfortable reading level.
Refer to @sec-reviewing-batch-histograms and @sec-reviewing-batch-box-plots for further information.

Now that we know which documents are scoring highly, we can begin revising them.
The next step is to review any grammar issues that may be contributing to overly-long sentences.
Click on the **Grammar** icon to display any grammar issues detected in the documents.
First select the **Long Sentences** subitem, as shown below:

![](images/batchlongsentences.png)

Here we can see which documents have the most overly-long sentences, as well as where the longest sentences are.
Once we have found a document of interest, we may want to review it in greater detail.
Select a document in this list and then click the `r keys("Subproject")` button on the **Home** tab.
This will create a [standard project](#sec-creating-standard-project), where we can review the long sentences individually.
We can also view the document with these sentences highlighted in their original context.
Note that standard projects can be created this way from any list which includes the document names.

Other tabs in the **Grammar** section are also available to help improve your documents.
If any of these grammatical issues are encountered, then lists for [wordy items](#sec-reviewing-batch-grammar), clichés, repeated words, lowercased sentences, and conjunction-starting sentences will be included.
For the purpose of shortening sentences, the **Repeated Words** and **Wordy Items** pages should be reviewed.

Once some of the documents have been revised, you can reload the batch project with the `r keys("F5")` button on your keyboard.
As we can see in this updated Flesch-Kincaid histogram, there is already some improvement in this batch.
There are no longer any documents scoring above the 12^th^ grade, and only 10 documents remain in the 10–12 grade range.

```{r echo=F, fig.align='center', out.width='75%'}
knitr::include_graphics("images/histoimproved.png")
```

\newpage

## Adding Descriptive Labels to Documents {#sec-adding-labels-to-batch}

Sometimes documents that we receive do not have descriptive names that are easily recognizable.
An example of this are downloaded webpages that may have names such as "index.html" or "2A67B2H.html."
In this example, we will show how to include descriptive labels next to our documents in a batch so that we can distinguish between them.

:::{.wrapfigure data-latex="{r}{0.5\\textwidth}" style="width: 48%;"}
![](images/group-label-descselected.png){width=48%}
:::

On the **Home** tab of the ribbon, click the `r keys('New')` button. When prompted for which type of project to create, select **Batch Project**.
Once the **New Project Wizard** appears, click the `r keys('Add folder...')` button.
On the **Select Directory** dialog, enter the folder path containing your documents and then click `r keys('OK')`.
Now we will be shown the **Select Labeling** dialog.

On this dialog, we can either specify a single label for all documents or use the documents’ metadata to create unique descriptions for each one.
For this example, we are wanting to include unique, descriptive labels for each document, so leave **Use documents’ descriptions** selected and click `r keys('OK')`.

Now, the program will load the files from the folder that we had selected. For example, below is a list of files where each one has the same name:

![](images/wizardbatchselectfilessamenames.png)

Because we had selected **Use documents' descriptions** for our labeling, then the titles from the documents will be extracted when the analysis begins.
From there, these titles will be shown as descriptive labels next to each document in the results.
Click `r keys('Finish')` to begin the analysis, and once the project appears, select **Raw Scores** under **Readability Scores**:

```{r echo=F, fig.align='center', out.width='50%'}
knitr::include_graphics("images/batch-desc-labels-scores.png")
```

Note how there is a **Label** column next to the **Document** column.
Despite the documents all having the same name, we can use this column will help us differentiate between them.

\newpage

## Grouping Documents in a Batch {#sec-grouping-docs-in-batch}

Sometimes when creating a batch, we may want to group the documents within it.
For example, clusters of documents within the batch may be from different websites, authors, or studies.
By adding group labels to these clusters, we can compare them in the results.
In this example, we will show how to add group labels to a batch of documents and how to view them in the results.

On the **Home** tab of the ribbon, click the `r keys('New')` button. When prompted for which type of project to create, select **Batch Project**.
When the **New Project Wizard** appears, click the `r keys('Add folder...')` button.
On the **Select Directory** dialog, enter the folder path containing your documents and then click `r keys('OK')`.
Now we will be shown the **Select Labeling** dialog.

On this dialog, we can either specify a single label for all documents or use the documents’ metadata to create unique descriptions for each one.
For this example, we are wanting to group this folders’ documents together, so select **Use a grouping label**, enter a label (e.g., *Notes*) and click `r keys('OK')`.

```{r echo=F, fig.align='center', out.width='50%'}
knitr::include_graphics("images/group-label-notes.png")
```

Repeat this process with another folder, but enter a different grouping label.
For example, we could select a folder of help examples and apply the label *Examples* to it:

```{r echo=F, fig.align='center', out.width='50%'}
knitr::include_graphics("images/group-label-examples.png")
```

::: {.notesection data-latex=""}
You can apply a group label to all selected documents by clicking the group button above the list.
:::

After adding your documents, click `r keys('Finish')`.
When the project appears, select **Raw Scores** under **Readability Scores**.
Here we can see a list of documents, along with their group labels next to them:

```{r echo=F, fig.align='center', out.width='75%'}
knitr::include_graphics("images/batch-group-labels-scores.png")
```

Here, we can sort by group or scores and see how the groups compare. In the above example, we can see that the *Tests* group is scoring poorly.

Grouping is also shown in the readability graphs. For example, if we included a Fry graph, then it may appear as such:

```{r echo=F, fig.align='center', out.width='75%'}
knitr::include_graphics("images/fry-grouped.png")
```

Here, we can see the *Tests* group again scoring rather high, as much of this group’s documents are clustering in the higher grade ranges.