```{r}
#| include: false
#| eval: true

source('../R/appdown.r')
```

# Technical Overviews

## Introduction {#sec-intro}

`r drop_cap('When')` writing for a target audience or classifying documents for specific age groups, readability formulas are invaluable tools.
They help determine the minimum age group that can quickly process reading material by using an analytical approach.
This approach uses factors such as sentence length, word difficulty, and word familiarity.

Most readability scores represent the grade level of the youngest reader that can understand a document.
They can also determine how easily a more broad audience can process it. For example, most magazine and newspaper articles should aim for scores around the 14–16 age range.
This is not because most readers of newspapers are in this age group. It is because this type of material should be easy to read for most age groups.
If an article has numerous complex and uncommon words, then it will take much longer to read and understand. (It will also make it less enjoyable to read.)
These are not qualities appropriate for something meant to be read quickly by most readers.

Note that these tests only determine the reading level of material based on how easy it is to process.
They do not consider the content or themes of a given work. The age level reported by a test score only reflects the age group that can comprehend a document.
It does not reflect whether the topics covered in the material are meant for that age group. If you are classifying books into age groups, you should first review them for any mature topics.
Then you should use readability tests to determine their comprehension levels.

\newpage

## How Tests are Calculated {-}

All readability formulas rely on factors such as sentence length, syllable counts, character counts, or word familiarity.
Which factors are used vary from test to test, but most tests use between one to three of these factors to gauge a document's difficulty.

::: {.minipage data-latex="{\textwidth}"}
Where readability tests may differ is how they are calculated. Most tests are performed using the following methods:

- linear regression equations
- lookup tables
- graphs
:::

The vast majority of tests use multiple linear regressions. Basically, multiple linear regression is a statistical method for modelling the relationship between a dependent variable and two or more independent variables (i.e., predictors). In the case of readability tests, the dependent is human-judged grade levels for a set of samples, while the independents are factors such as the samples' sentence lengths and syllable counts. A multiple regression is performed to determine the strongest predictors (usually the top two), and the prediction equation created by the analysis will be the new readability formula.

Another method is lookup tables, where the intersection of factors (e.g., number of sentences and number of syllables) are found in a table. When located, the position in the table will indicate the grade level. Examples of table-based tests include Wheeler-Smith and New Dale-Chall. (Refer to table \@ref(tab:wheeler-smith-conversion-table) for an example.)

The final method also relies on finding the intersection of factors, but on a graph instead of a table. Most of these plots are divided into bands or brackets, with each of these regions representing a grade or difficulty level. For example, Fry and Raygor use polygonal bands, while Flesch Reading Ease uses brackets along a “ruler”:

```{r echo=F, fig.show = 'hold', out.width='50%', fig.cap='Comparison of bands vs. brackets'}
knitr::include_graphics("../images/frygraph.png")
knitr::include_graphics("../images/flesch-chart.png")
```

Once the intersection of two factors is located on the plot, the band or bracket that the intersection falls into will indicate the score.

```{r, results='asis', eval=T, echo=F}
OptionsDesc <- "(Note that the program will include both forms of these tests in the results.)"

glue('As a final note, there are a few hybrid tests which can be calculated via a regression equation or graph. These tests were initially constructed as regression equations, and this is the preferred method for performing them. The tests\' authors, however, would also offer a graphical version as a quicker and simpler way for performing these tests. Examples of these tests include Flesch Reading Ease and Crawford.
$if_else(UserManualMode, OptionsDesc, "")^', .open='$', .close='^')
```

## Grade-level Clamping {#sec-grade-level-clamping}

A key difference between graph and table-based tests versus regression-based tests is how the former has defined upper limits for their scores. For example, graph-based tests acquire their scores by finding the intersection of certain factors (e.g., sentence length) within a set a bands. These bands represent grades, and there are a specific set of grade bands available. As an example, a [Fry](#sec-fry-test) graph has bands ranging from 1^st^ grade to 17^th^ (i.e., college):

```{r echo=F, fig.align='center', out.width='75%'}
knitr::include_graphics("../images/frygraph.png")
```

Likewise, table-based tests take a set of factors and look up the score from a table. These tables have a specific set of grade levels and will also have an upper limit. (Refer to table \@ref(tab:wheeler-smith-conversion-table) for an example.)

In contract, tests which use regression equations do not have upper limits. In theory, a document with extreme factors (e.g., abnormally long sentences) could yield scores above grade 19 (i.e., PhD level). To keep results sensical, such scores should be clamped to 19 and be displayed as 19+. This is done for a number of reasons.

First, scores such as 27^th^ grade do not reflect reality. To describe a document as only being understandable by a PhD is relatable. To say that a document can only be processed by someone in the 27^th^ grade, however, makes little sense. Another way to view this is that 19+ implies a document's failure to be readable—similar to an *F* on a test.

Second, because graph and table-based tests are bound to sensical grade scales, it is reasonable to treat regression-based tests the same way. For example, a document scoring 16+ for New Dale-Chall should clamp tests such as Flesch-Kincaid to 19+, thus keeping their scores on a similar scale. In other words, grade and table-based tests were designed for grade scales from 0–19 (sometimes even lower). Likewise, it is reasonable to assume that was the intention of regression-based tests as well.

Finally, the source materials for these formulas cite example scores within 0–19. Again, it can be inferred that the authors' intention was for documents to be bound to a reasonable grade scale.

```{r, results='asis', eval=UserManualMode, echo=F, include=UserManualMode}
glue('Although not recommended, it is possible to create a copy of any regression-based test and remove this clamping. (Refer to ch. \\@ref(sec-custom-test-no-clamping) for an example.)')
```

## How Tests can Fail {-}

Most readability tests will return a result, even when the document being reviewed contains extreme difficulty factors.
For example, with table-based tests, documents with long sentences and/or numerous unfamiliar words will fall within the top bracket of the look-up table.
(Refer to table \@ref(tab:wheeler-smith-conversion-table) for an example).
Likewise, plugging a document's statistics into a regression-based test will also produce a result without issue (although extreme results may need to be clamped, see @sec-grade-level-clamping).

It is possible, however, for certain graphical tests to not return a meaningful result. Tests such as Fry and Schwartz use plots that are divided into bands (i.e., polygonal strips) which represent different grade levels. To produce a result, these tests find the intersection of a document's statistics along the plot's axes. Once the intersection is found, the band that the point falls within will indicate the grade level of the document.

```{r echo=F, fig.align='center', fig.cap='Example of a graph with grade-level bands', out.width='75%'}
knitr::include_graphics("../images/schwartz.png")
```

```{r, results='asis', eval=T, echo=F}
OptionsDesc <- "When this occurs, the program will indicate that the test failed and explain which factor (e.g., high syllable count) caused the failure."

glue('For most documents this will yield a result, but extreme documents may fall outside of the grade-level bands. (This can happen if there are too many difficult words or lengthy sentences.)
$if_else(UserManualMode, OptionsDesc, "")^', .open='$', .close='^')
```
